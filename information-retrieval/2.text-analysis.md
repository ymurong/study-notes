
- [Content of Table](#content-of-table)
  - [Statistical properties of text](#statistical-properties-of-text)
    - [Zipf’s law](#zipfs-law)
    - [Heap’s law](#heaps-law)
  - [Text Analysis pipeline](#text-analysis-pipeline)
    - [Pipeline](#pipeline)
    - [Stop-word removal](#stop-word-removal)
    - [Stemming](#stemming)
      - [Different types](#different-types)
      - [Krovetz stemmer Approach](#krovetz-stemmer-approach)
      - [Evaluation](#evaluation)
    - [Phrases](#phrases)
      - [Part of speech (POS)](#part-of-speech-pos)
      - [Different ways of handling phrases](#different-ways-of-handling-phrases)


# Content of Table
## Statistical properties of text
### Zipf’s law
- Word Frequency **Probability**(P_r) is inversely proportional to **Ranking**.
- $Rank * P_r$ = Const' (stable to a value)
- English's const' $\approx$ 0.1
- Top frequency words would slightly deviate from the law
- Low frequency words would slightly deviate from the law
  

###  Heap’s law
- \# unique words is sub-linear to \# words in a collection
- the more words -> not that much more unique words
- vocab = k * $words^\beta$ (10<=k<=100, $\beta \approx 0.5$)

## Text Analysis pipeline

### Pipeline
- Remove white-spaces and punctuation (common)
- Lower-case (common)
- Remove stop-words (somewhat common)
- Stemming (less common)
- Deal with phrases (uncommon)
- Apply language-specific precessing rules

### Stop-word removal
- Frequency-based
    - Set a frequency threshold f 
    - Remove words with the frequency higher than f
- Dictionary-based
  - create a dictionary of stop-words
  - remove words that occur in this dictionary 

### Stemming
#### Different types
- Algorithmic stemming: using small program to decide, based on knowledge of word suffixes for a particular language -> Porter stemmer (lengthy rule based, FP, FN)
- Dictionary-based stemming: run -> running, runs, runned. runly (New-words problem)
- Hybrid stemming (Krovetz stemmer) -> lower FP than Porter but also tends to have higher FN -> tend to have more full words
- Porter has higher recall, but lower precision
- More complicated -> Low FN, but high FP

#### Krovetz stemmer Approach 
1. Before stemming, check to see whether word is valid
2. if found, leave it as is/ or stemmed based on exception entry
3. if not found, apply algorithmic stemming (remove suffixes)
4. check the dictionary again
5. if not found apply rules to modify the ending

#### Evaluation
- FP: organization/organ -> same stem but change meaning 
- FN: european/europe -> same meaning but stem changed

 
### Phrases
#### Part of speech (POS)
A POS tagger marks the words in a text with labels corresponding to the part-of-speech of the word in that context. Taggers are based on statistical (Hidden Markov Model?) or rule-based approaches and trained with large labeled corpus

- NN (singular noun), NNS (plural noun), VB (verb), VBD (verb, past tense), VBN (verb, past participle), IN (preposition), JJ (adjective), CC (conjunction, "and", "or"), PRP (pronoun, "he", "she"), and MD (modal auxiliary, "can", "will")

#### Different ways of handling phrases
1. Detect noun phrases using a part-of-speech tagger (POS)
    - beforehand find all noun phrases in collection and match them with the query???
    - sequences of nouns (marketing strategy)
    - adjectives followed by nouns (agricultural chemicals)
    - indexing form (nouns phrase, freq?/pos?) exact match?????
    - neatest but slowest (medical docs better this one)
2. Detect phrases at the query processing time (based on query frequency)
    - identified either by user / POS tagging
    - use an index with word positions (word, position)
    - phrases can be identified on the query
    - not restricted to adjacent groups of words
3. Use frequent n-grams, e.g., bigrams and trigrams (based on corpus frequency)
    - quickest but dirtiest 
    - incoporate with ranking algo
    - indexing for each document (n-gram, freq, ranking)
