- [Part 1 - Neural Methods](#part-1---neural-methods)
  - [Learning to Rank vs Neural Ranking](#learning-to-rank-vs-neural-ranking)
  - [Advantages](#advantages)
  - [Motivations](#motivations)
  - [Reranking with static embeddings](#reranking-with-static-embeddings)
    - [Embedding similarity matrix](#embedding-similarity-matrix)
    - [Deep Relevance Matching Model (DRMM)](#deep-relevance-matching-model-drmm)
  - [Contextualized embeddings](#contextualized-embeddings)
    - [BERT](#bert)
      - [Limitations](#limitations)
      - [Solutions](#solutions)
  - [Transformer Approaches for (re)ranking](#transformer-approaches-for-reranking)
    - [Cross-Encoder](#cross-encoder)
    - [Dense Retrieval (for the whole collection)](#dense-retrieval-for-the-whole-collection)
    - [Learned sparse retrieval (for the whole collection)](#learned-sparse-retrieval-for-the-whole-collection)
- [Part 2 - Dense Retrieval](#part-2---dense-retrieval)
    - [Sparse Representations](#sparse-representations)
    - [Dense Representations](#dense-representations)
      - [Brutal force](#brutal-force)
      - [Approximate Nearest Neighbor Search (Solution)](#approximate-nearest-neighbor-search-solution)
    - [Distance-based Approaches](#distance-based-approaches)


# Part 1 - Neural Methods
## Learning to Rank vs Neural Ranking
- learning to rank: given features, how can we better optimize ranking
- neural ranking: given input text, how can we better represent it (term embeddings, dense retrieval

## Advantages
1. less hand crafting
2. soft matching

## Motivations
Transformer way better than traditional NN and BM25

## Reranking with static embeddings
- word2vec, GloVe, FastText 
- based on co-occurences

### Embedding similarity matrix

### Deep Relevance Matching Model (DRMM)

## Contextualized embeddings

### BERT
#### Limitations
- Computationally expensive

#### Solutions
- Multi-stage ranking pipeline: BM25 + rerank with transformers
- Pre-compute doc representations ??? HOW


## Transformer Approaches for (re)ranking
### Cross-Encoder
- Input: Q-D pair
- Model outputs score
- slow but robust
- during inference, compute fixed query for all documents that needs to be reranked

### Dense Retrieval (for the whole collection)
- convert documents to vectors (offline) -> build the ANN index
- query time we match the query with the document vectors already created
- score by taking the dot product (Q,D)
- ANN index: put document vector into the ANN index: given a query vector -> what's the top k closest document vectors
- Faster, less effective & less robust

### Learned sparse retrieval (for the whole collection)
- input Q / D
- learn some term weights (replacing the tfidf weights) directly (term-document matrix)
- faster than cross-encoder



# Part 2 - Dense Retrieval


### Sparse Representations

### Dense Representations
#### Brutal force 
too slow
#### Approximate Nearest Neighbor Search (Solution)
- k-means of doc representations


### Distance-based Approaches 