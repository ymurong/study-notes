
Now every company is talking about integrating generative AI to their existing products and chatgpt is one of them. Do you think it can be dangerous (data privacy / GDPR) for companies to feed their data to openai api to fine tune so that they could have a better Q/A chatbot for instance? If so, is there any alternatives or measures that can help to minimize the risk?


# Responsible Data Management

Automated hiring systems
- sourcing, screening (skills, personalities), background check
- efficiency for job seeker, efficiency for employer, workforce diversity
- Just the name of CV changes -> bias and fairness issues 
- tendency to discriminate more 

Amazon scraps secret AI recruiting tool that showed bias against women (2018)

- new york city local law -> bias audit be conducted on a automated decision tool -> notified about the use of the tool and notified about the qualifications that would be used...


Accenture: ChatGPT

Risks: Chat with chatgpt, ask the risks, how it deal with the GDPR illegal to send ... does not anonymize ... external org has no control


## Bias in computer systems

- Pre-existing: origins in society
- Technical: technical properties of a system
- Emergent: feedback loops, arises due to context of use









