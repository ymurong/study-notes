- [Content of Table](#content-of-table)
  - [Objectives](#objectives)
  - [Text Indexing](#text-indexing)
  - [Map-Reduce](#map-reduce)
    - [Second order function](#second-order-function)
    - [Why it is good?](#why-it-is-good)
      - [Distributed programming common challenges](#distributed-programming-common-challenges)
      - [Advantanges](#advantanges)
    - [Phases](#phases)
    - [Shuffling (and Sorting)](#shuffling-and-sorting)
      - [Key assignment](#key-assignment)
      - [Key skew](#key-skew)
      - [Solution](#solution)
        - [Combiner for averaging](#combiner-for-averaging)
    - [Tips for MapReduce in Practice](#tips-for-mapreduce-in-practice)
    - [Criticisms of MapReduce](#criticisms-of-mapreduce)
      - [Too low-level](#too-low-level)
      - [Poor Implementation](#poor-implementation)
    - [Why it becomes so successful](#why-it-becomes-so-successful)



# Content of Table
## Objectives 
- Describe the anatomy of a MapReduce job 
- Analyse the suitability of the MapReduce approach for a given problem
- Design implementations for MapReduce programs 

## Text Indexing
- Inverted Index (words → documents ) process takes O(N) time 
- With M machines, can we lower the time to O(N/M)?


## Map-Reduce
### Second order function
- A second order function takes another function as argument
- map take a first order function and a list to produce another list 
- reduce takes a second order function and a list, and produce a aggregated result
- f_map
  - (k1, v1) → [(k2, v2)]
- f_reduce
  - (k2, [v2, ..., vn]) → (k2, v3)

### Why it is good?
#### Distributed programming common challenges
- Scheduling (which piece of work to execute when) 
- Concurrency (how to run certain parts of our computation in parallel) 
- Fault Tolerance (how to handle machine/disk failures)

#### Advantanges
- Programmer only has to think about the logic of their program  (expressed in the mapper and reducer functions) 
- Runtime (e.g., Hadoop) automatically takes care of scheduling, concurrency, fault tolerance

### Phases
- Map 
  - Read input data 
  - Generate intermediate results via f_map 
- Shuffle‚·
  - Move data from mappers to reducers
- Reduce
  - Execute f_reduce and collect output


###  Shuffling (and Sorting)
How do efficiently assign the work for the k keys to our r reducer nodes?

- Hash-partitioning: determine reducer node r for a key k as follows:           r = hash(k) mod R 

#### Key assignment
#### Key skew
- intermediate key distribution is unbalanced
- Different reducers will have different work loads 
- In the worst case, we have to wait for one reducer  to finish the work for one large key group!
#### Solution
- Combiners
  - pre-aggregating (combine) data before shuffling
##### Combiner for averaging 
using combiner to compute total_sum and total_count



### Tips for MapReduce in Practice
- Have fewer reducer nodes than intermediate keys to keep nodes busy!
- Combiners can help, but sometimes a custom pre-aggregation during the
map-phase is even better
- Very advanced MapReduce programs exploit the sortedness
of the reduce inputs
  - In a join implementation, we can leverage this to see one join input before the other


### Criticisms of MapReduce
#### Too low-level
- No schema 
#### Poor Implementation
- MapReduce does not index data like an RDBMS
  - MapReduce has to scan the whole input data!
- No optimised execution for complex programs consisting of
multiple MapReduce jobs
  - Intermediate results always written to distributed storage in between!
- Lack of DBMS compatibility
  - Visualization
  - Data migration
  - Database design

### Why it becomes so successful
- Extracting content from web pages (information extraction)
- Ranking of search results based on link structure of the web (graph processing)

