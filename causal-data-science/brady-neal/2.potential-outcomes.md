- [Table of Content](#table-of-content)
  - [Potential Outcomes](#potential-outcomes)
  - [Individual Treatment Effect](#individual-treatment-effect)
  - [Fundamental Problem of Causal Inference](#fundamental-problem-of-causal-inference)
  - [Getting Around Fundamental Problem](#getting-around-fundamental-problem)
    - [Average Treatment Effects (causal quantity)](#average-treatment-effects-causal-quantity)
      - [Example: association is not causation](#example-association-is-not-causation)
    - [What assumptions would make ATE equal to the associational difference?](#what-assumptions-would-make-ate-equal-to-the-associational-difference)
      - [Ignorability](#ignorability)
      - [Exchangeability](#exchangeability)
      - [Identifiability](#identifiability)
    - [Conditional Exchangeability (unconfoundedness)](#conditional-exchangeability-unconfoundedness)
      - [Adjustment Formula (identify ATE)](#adjustment-formula-identify-ate)
    - [Positivity (overlap)](#positivity-overlap)
    - [Tradeoff between Positivity and Unconfoundedness](#tradeoff-between-positivity-and-unconfoundedness)
    - [Extrapolation](#extrapolation)
    - [No interference](#no-interference)
    - [Consistency](#consistency)
    - [Summary](#summary)
  - [Some Terminology](#some-terminology)
  - [Problem: effect of sodium intake on blood pressure](#problem-effect-of-sodium-intake-on-blood-pressure)



# Table of Content

## Potential Outcomes
- Potential outcome $Y(t)$ denotes what your outcome would be, if you were to take treatment t. 
- Observed outcome is denoted as $Y$, not all potential outcome can be observed
- $Y(t)$ is usually treated as random variable as different individuals will have different potential outcomes
- $Y_{i}(t)$ is usually treated as non-random because the subscript $i$ means that we are conditioning on individualized information.

## Individual Treatment Effect
- $\tau_{i} = Y_{i}(1) - Y_{i}(0)$
- ITEs are some of the main quantities that we care about in causal inference

## Fundamental Problem of Causal Inference
- Problem: Causal effect cannot be observed as we cannot observe the counterfactuals, but causal inference is about making causal claims based on this causal effect
- This problem is unique to causal inference as ML only need to predict the observed outcome $Y_{i}$ but causal inference also need to evaluate $Y_{i}|do(T)$, also denoted as $Y_{i}(t)$

## Getting Around Fundamental Problem

### Average Treatment Effects (causal quantity)
- $E_{i}[Y_{i}(1) - Y_{i}(0)]$
- In simple form: $E[Y(1) - Y(0)] = E[Y(1)]-E[Y(0)]$
- Associational Difference: $E[Y|T=1]-E[Y|T=0]$
- ATE is usually not equal to associational difference as association is not causation

#### Example: association is not causation
Sleeping with shoes on is strongly correlated with waking up with a headache
- Common cause: drinking the night before
  - confounding effect
  - groups are not comparable (not randomized groups: shoe-sleepers tends to have more drunk people) 

### What assumptions would make ATE equal to the associational difference?

#### Ignorability
- if we assume ignorability, then we could condition on treatment as both potential outcome are independent from treatment 
- $(Y(1), Y(0)) \perp \!\!\! \perp T$
- $E[Y(1)]-E[Y(0)] = E[Y(1)|T=1]-E[Y(0)|T=0] (ignorability)$
- $E[Y|T=1]-E[Y|T=0]$
- if you remove/block the confounding effect, then ignorability applies


#### Exchangeability
- switch treatment group with control group 
- $E[Y(1)|T=1] = E[Y(1)|T=0] = E[Y(1)]$
- $E[Y(0)|T=1] = E[Y(0)|T=0] = E[Y(0)]$
- The potential outcome is independent from treatment

#### Identifiability
- causal quantity (e.g. $E[Y(t)]$) is identifiable if we can compute it from a purely statistical quantity (e.g. $E[Y|t]$) => we need ignorability (potential outcome is independent from treatments)
- ignorability is unrealistic as confounding exists in most data
- however, this could be made possible by randomized experiments (RCT) -> eliminate the confounding effect (that edge !!!!)
- two assumptions: unconfoundedness and positivity

### Conditional Exchangeability (unconfoundedness)
- $(Y(1), Y(0)) \perp \!\!\! \perp T | X$
- when we use conditional exchangeability, we block the confounding effect
- $E[Y(1)-Y(0)|X]$ $\\$
  $= E[Y(1)|X]-E[Y(0)|X]$ <- linear expectation $\\$
  $= E[Y(1)|T=1, X]-E[Y(0)|T=0,X]$ <- apply conditonal exchangeability  $\\$
  $= E[Y|T=1, X]-E[Y|T=0,X]$ <- potential outcome Y(1) given T=1 is just the observed outcome given T=1
- We turn causal quantity into statistical quantity

#### Adjustment Formula (identify ATE)
- Identity ATE from conditional exchangeability
- $E[Y(1)-Y(0)]$ $\\$
  $= E_{X}E[Y(1)-Y(0)|X]$$\\$
  $= E_{X}[E[Y|T=1,X]-E[Y|T=0,X]]$ <- using conditional exchangeability$\\$

> Unconfoundedness is untestable as we never know whether we have unobserved confounders or not. Inituitively, the best thing we can do is to observe and fit as many covariates into X as possible to ensure unconfoundedness

### Positivity (overlap)
- 2nd important assumption
- all subgroups of the data with different covariates have some probability of receiving any value of treatment
- $0<P(T=1|X=x)<1$
- it gurantees that we wont have division by zero (check equation 2.10 and 2.11)
- another name: overlap 
- the covariate distribution of treatment group to overlap with the covariate distribution of the control group
- overlap between $P(X|T=0)$ and $P(X|T=1)$

### Tradeoff between Positivity and Unconfoundedness
- curse of dimensionality 
- more covariates (stronger unconfoundedness), but less overlap (weaker positivity)

### Extrapolation
- violations of the positivity assumption can actually lead to demanding too much from models and getting very bad behavior in return
- extrapolates towards another group which does not have any observational data

### No interference
- my outcome is unaffected by anyone else's treatment
- my outcome is only a function of my own treatment

### Consistency
- If treatment is T, then the observed outcome Y is the potential outcome under treatment T.
- In other words, it is not allowed to have multiple definition of T=1 (getting a chiwawa/golden hair dog)
- T is the random variable, t is the specific value of the R.V T

### Summary
- unconfoundedness
- positiveness(overlap)
- no interference
- consistency


## Some Terminology
- Estimand: any quantuty we want to estimate
  - Causal estimand (e.g. $E[Y(1)-Y(0)]$)
  - Statistical estimand (e.g. $E_{X}[E[Y|T=1,X] - E[Y|T=0, X]]$)
- Estimate: approximation of some estimand, using data
- Estimation: process for getting from data + estimand to estimate
- Causal Estimand -> Identification -> Statistical Estimand -> Estimation -> Estimate

## Problem: effect of sodium intake on blood pressure

